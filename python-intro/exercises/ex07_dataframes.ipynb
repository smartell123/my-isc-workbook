{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0d752e8-9ce7-408f-96b3-a9748acecb26",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Exercise 7: Reading Tabular Data into DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4321ca-6c64-4170-b617-d93690ac533f",
   "metadata": {},
   "source": [
    "## Aim: Learn what DataFrames are and practice using them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d9ad99-28ad-49ed-8318-58e2bc3d519f",
   "metadata": {},
   "source": [
    "### Issues covered:\n",
    "- Importing the `pandas` library\n",
    "- Using `pandas` to load a simple CSV data set\n",
    "- Get information about the DataFrames we make"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b64853-3332-482a-b1b0-08a686a45386",
   "metadata": {},
   "source": [
    "## 1. Let's import `pandas` and make some DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577d413a-d2c3-4d3a-b8c7-bb87834e34b4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Import `pandas`, then create a dataframe using the `data/weather.csv` file and print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "507ca506-e488-4a7e-88f7-25a2aa4cfaae",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "clear_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date   Time  Temp  Rainfall\n",
      "0  2014-01-01  00:00  2.34      4.45\n",
      "1  2014-01-01  12:00  6.70      8.34\n",
      "2  2014-01-02  00:00 -1.34     10.25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "weather_data = pd.read_csv('../data/weather.csv')\n",
    "print (weather_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a8d403-57a6-40de-aed0-23080192918a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Create a new dataframe which indexes by `Date` and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "355a9346-ee50-403e-8c5c-0996a6e2be4e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "clear_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Time  Temp  Rainfall\n",
      "Date                             \n",
      "2014-01-01  00:00  2.34      4.45\n",
      "2014-01-01  12:00  6.70      8.34\n",
      "2014-01-02  00:00 -1.34     10.25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "weather_data_date = pd.read_csv('../data/weather.csv', index_col='Date')\n",
    "print (weather_data_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4af1af5-eec2-4d74-90a2-e93fcacbba39",
   "metadata": {},
   "source": [
    "##Â 2. Let's practice using some dataframe methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3f4d2e-5bc5-480b-a5e9-f37453ef597f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "What is the memory usage of the dataframe in bytes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61051add-b15d-429a-a74b-292681e36bac",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "clear_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3 entries, 2014-01-01 to 2014-01-02\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Time      3 non-null      object \n",
      " 1   Temp      3 non-null      float64\n",
      " 2   Rainfall  3 non-null      float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 96.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "weather_data_date.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b85f457-b243-47b8-a996-ac7e5c5750ab",
   "metadata": {},
   "source": [
    "What command can you use to find the dataframe's column names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "258e77ea-532c-4b27-9682-2eb995d9952d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "clear_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Time', 'Temp', 'Rainfall'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(weather_data_date.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69428372-654c-467e-87a1-6b5b0e5d7d09",
   "metadata": {},
   "source": [
    "Swap the rows and columns and `print` the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c013233-5e0e-443c-a996-434e5c1d85c8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "clear_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date     2014-01-01 2014-01-01 2014-01-02\n",
      "Time          00:00      12:00      00:00\n",
      "Temp           2.34        6.7      -1.34\n",
      "Rainfall       4.45       8.34      10.25\n"
     ]
    }
   ],
   "source": [
    "print(weather_data_date.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2200f4b4-ac33-42ad-9558-40395f921eaf",
   "metadata": {},
   "source": [
    "Find the mean and standard deviation of the weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38848201-e994-4427-81fb-23e08cac9b60",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "clear_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Temp   Rainfall\n",
      "count  3.000000   3.000000\n",
      "mean   2.566667   7.680000\n",
      "std    4.024790   2.955791\n",
      "min   -1.340000   4.450000\n",
      "25%    0.500000   6.395000\n",
      "50%    2.340000   8.340000\n",
      "75%    4.520000   9.295000\n",
      "max    6.700000  10.250000\n"
     ]
    }
   ],
   "source": [
    "print(weather_data_date.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2451284-57f1-4638-886a-73de3e6256f6",
   "metadata": {},
   "source": [
    "## 3. Extension: Some Dataframe Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357f28d8-74d3-49c8-a862-13ee57459755",
   "metadata": {},
   "source": [
    "1. Find the first three rows of data in `data/americas_gdp.csv` using `head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62eaf73a-acdc-4eb0-89d1-ef1fffd0640c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "clear_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  continent    country  gdpPercap_1952  gdpPercap_1957  gdpPercap_1962  \\\n",
      "0  Americas  Argentina     5911.315053     6856.856212     7133.166023   \n",
      "1  Americas    Bolivia     2677.326347     2127.686326     2180.972546   \n",
      "2  Americas     Brazil     2108.944355     2487.365989     3336.585802   \n",
      "\n",
      "   gdpPercap_1967  gdpPercap_1972  gdpPercap_1977  gdpPercap_1982  \\\n",
      "0     8052.953021     9443.038526    10079.026740     8997.897412   \n",
      "1     2586.886053     2980.331339     3548.097832     3156.510452   \n",
      "2     3429.864357     4985.711467     6660.118654     7030.835878   \n",
      "\n",
      "   gdpPercap_1987  gdpPercap_1992  gdpPercap_1997  gdpPercap_2002  \\\n",
      "0     9139.671389     9308.418710    10967.281950     8797.640716   \n",
      "1     2753.691490     2961.699694     3326.143191     3413.262690   \n",
      "2     7807.095818     6950.283021     7957.980824     8131.212843   \n",
      "\n",
      "   gdpPercap_2007  \n",
      "0    12779.379640  \n",
      "1     3822.137084  \n",
      "2     9065.800825  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "americas_data = pd.read_csv('../data/americas_gdp.csv')\n",
    "print (americas_data.head(n=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcff88d3-f459-4139-abc0-3d87a3a9fbd2",
   "metadata": {},
   "source": [
    "2. Find the last 3 **columns** of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c90192-74f7-4064-993b-f650108f81ea",
   "metadata": {},
   "source": [
    "_Hint: You may need to change your view of the data then you can use `tail()`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aeeed721-06b5-4bf9-8f7b-326c52e8d23a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "clear_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         0            1            2            3   \\\n",
      "gdpPercap_1997  10967.28195  3326.143191  7957.980824  28954.92589   \n",
      "gdpPercap_2002  8797.640716   3413.26269  8131.212843  33328.96507   \n",
      "gdpPercap_2007  12779.37964  3822.137084  9065.800825  36319.23501   \n",
      "\n",
      "                         4            5            6            7   \\\n",
      "gdpPercap_1997  10118.05318  6117.361746  6677.045314  5431.990415   \n",
      "gdpPercap_2002  10778.78385  5755.259962  7723.447195  6340.646683   \n",
      "gdpPercap_2007  13171.63885  7006.580419   9645.06142  8948.102923   \n",
      "\n",
      "                         8            9   ...           15           16  \\\n",
      "gdpPercap_1997  3614.101285  7429.455877  ...   9767.29753  2253.023004   \n",
      "gdpPercap_2002  4563.808154  5773.044512  ...  10742.44053  2474.548819   \n",
      "gdpPercap_2007  6025.374752  6873.262326  ...  11977.57496  2749.320965   \n",
      "\n",
      "                         17           18           19           20  \\\n",
      "gdpPercap_1997  7113.692252  4247.400261  5838.347657   16999.4333   \n",
      "gdpPercap_2002  7356.031934  3783.674243  5909.020073  18855.60618   \n",
      "gdpPercap_2007  9809.185636  4172.838464  7408.905561  19328.70901   \n",
      "\n",
      "                         21           22           23           24  \n",
      "gdpPercap_1997  8792.573126  35767.43303  9230.240708  10165.49518  \n",
      "gdpPercap_2002  11460.60023  39097.09955  7727.002004  8605.047831  \n",
      "gdpPercap_2007  18008.50924  42951.65309  10611.46299  11415.80569  \n",
      "\n",
      "[3 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "americas_T = americas_data.T\n",
    "print (americas_T.tail(n=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3191ea41-a5c3-491b-95f4-3834376d692d",
   "metadata": {},
   "source": [
    "3. Use `help(data_americas.to_csv)` to figure out how writing to a CSV file works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "845a8b2a-99fb-4a84-bc5d-9570ceab556e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "clear_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method to_csv in module pandas.core.generic:\n",
      "\n",
      "to_csv(path_or_buf: 'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None' = None, sep: 'str' = ',', na_rep: 'str' = '', float_format: 'str | None' = None, columns: 'Sequence[Hashable] | None' = None, header: 'bool_t | list[str]' = True, index: 'bool_t' = True, index_label: 'IndexLabel | None' = None, mode: 'str' = 'w', encoding: 'str | None' = None, compression: 'CompressionOptions' = 'infer', quoting: 'int | None' = None, quotechar: 'str' = '\"', line_terminator: 'str | None' = None, chunksize: 'int | None' = None, date_format: 'str | None' = None, doublequote: 'bool_t' = True, escapechar: 'str | None' = None, decimal: 'str' = '.', errors: 'str' = 'strict', storage_options: 'StorageOptions' = None) -> 'str | None' method of pandas.core.frame.DataFrame instance\n",
      "    Write object to a comma-separated values (csv) file.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path_or_buf : str, path object, file-like object, or None, default None\n",
      "        String, path object (implementing os.PathLike[str]), or file-like\n",
      "        object implementing a write() function. If None, the result is\n",
      "        returned as a string. If a non-binary file object is passed, it should\n",
      "        be opened with `newline=''`, disabling universal newlines. If a binary\n",
      "        file object is passed, `mode` might need to contain a `'b'`.\n",
      "    \n",
      "        .. versionchanged:: 1.2.0\n",
      "    \n",
      "           Support for binary file objects was introduced.\n",
      "    \n",
      "    sep : str, default ','\n",
      "        String of length 1. Field delimiter for the output file.\n",
      "    na_rep : str, default ''\n",
      "        Missing data representation.\n",
      "    float_format : str, default None\n",
      "        Format string for floating point numbers.\n",
      "    columns : sequence, optional\n",
      "        Columns to write.\n",
      "    header : bool or list of str, default True\n",
      "        Write out the column names. If a list of strings is given it is\n",
      "        assumed to be aliases for the column names.\n",
      "    index : bool, default True\n",
      "        Write row names (index).\n",
      "    index_label : str or sequence, or False, default None\n",
      "        Column label for index column(s) if desired. If None is given, and\n",
      "        `header` and `index` are True, then the index names are used. A\n",
      "        sequence should be given if the object uses MultiIndex. If\n",
      "        False do not print fields for index names. Use index_label=False\n",
      "        for easier importing in R.\n",
      "    mode : str\n",
      "        Python write mode, default 'w'.\n",
      "    encoding : str, optional\n",
      "        A string representing the encoding to use in the output file,\n",
      "        defaults to 'utf-8'. `encoding` is not supported if `path_or_buf`\n",
      "        is a non-binary file object.\n",
      "    compression : str or dict, default 'infer'\n",
      "        For on-the-fly compression of the output data. If 'infer' and '%s'\n",
      "        path-like, then detect compression from the following extensions: '.gz',\n",
      "        '.bz2', '.zip', '.xz', or '.zst' (otherwise no compression). Set to\n",
      "        ``None`` for no compression. Can also be a dict with key ``'method'`` set\n",
      "        to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``} and other\n",
      "        key-value pairs are forwarded to ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "        ``bz2.BZ2File``, or ``zstandard.ZstdDecompressor``, respectively. As an\n",
      "        example, the following could be passed for faster compression and to create\n",
      "        a reproducible gzip archive:\n",
      "        ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      "    \n",
      "        .. versionchanged:: 1.0.0\n",
      "    \n",
      "           May now be a dict with key 'method' as compression mode\n",
      "           and other entries as additional compression options if\n",
      "           compression mode is 'zip'.\n",
      "    \n",
      "        .. versionchanged:: 1.1.0\n",
      "    \n",
      "           Passing compression options as keys in dict is\n",
      "           supported for compression modes 'gzip', 'bz2', 'zstd', and 'zip'.\n",
      "    \n",
      "        .. versionchanged:: 1.2.0\n",
      "    \n",
      "            Compression is supported for binary file objects.\n",
      "    \n",
      "        .. versionchanged:: 1.2.0\n",
      "    \n",
      "            Previous versions forwarded dict entries for 'gzip' to\n",
      "            `gzip.open` instead of `gzip.GzipFile` which prevented\n",
      "            setting `mtime`.\n",
      "    \n",
      "    quoting : optional constant from csv module\n",
      "        Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      "        then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      "        will treat them as non-numeric.\n",
      "    quotechar : str, default '\\\"'\n",
      "        String of length 1. Character used to quote fields.\n",
      "    line_terminator : str, optional\n",
      "        The newline character or character sequence to use in the output\n",
      "        file. Defaults to `os.linesep`, which depends on the OS in which\n",
      "        this method is called ('\\\\n' for linux, '\\\\r\\\\n' for Windows, i.e.).\n",
      "    chunksize : int or None\n",
      "        Rows to write at a time.\n",
      "    date_format : str, default None\n",
      "        Format string for datetime objects.\n",
      "    doublequote : bool, default True\n",
      "        Control quoting of `quotechar` inside a field.\n",
      "    escapechar : str, default None\n",
      "        String of length 1. Character used to escape `sep` and `quotechar`\n",
      "        when appropriate.\n",
      "    decimal : str, default '.'\n",
      "        Character recognized as decimal separator. E.g. use ',' for\n",
      "        European data.\n",
      "    errors : str, default 'strict'\n",
      "        Specifies how encoding and decoding errors are to be handled.\n",
      "        See the errors argument for :func:`open` for a full list\n",
      "        of options.\n",
      "    \n",
      "        .. versionadded:: 1.1.0\n",
      "    \n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "        are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      "        starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      "        ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      "    \n",
      "        .. versionadded:: 1.2.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    None or str\n",
      "        If path_or_buf is None, returns the resulting csv format as a\n",
      "        string. Otherwise returns None.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    read_csv : Load a CSV file into a DataFrame.\n",
      "    to_excel : Write DataFrame to an Excel file.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
      "    ...                    'mask': ['red', 'purple'],\n",
      "    ...                    'weapon': ['sai', 'bo staff']})\n",
      "    >>> df.to_csv(index=False)\n",
      "    'name,mask,weapon\\nRaphael,red,sai\\nDonatello,purple,bo staff\\n'\n",
      "    \n",
      "    Create 'out.zip' containing 'out.csv'\n",
      "    \n",
      "    >>> compression_opts = dict(method='zip',\n",
      "    ...                         archive_name='out.csv')  # doctest: +SKIP\n",
      "    >>> df.to_csv('out.zip', index=False,\n",
      "    ...           compression=compression_opts)  # doctest: +SKIP\n",
      "    \n",
      "    To write a csv file to a new folder or nested folder you will first\n",
      "    need to create it using either Pathlib or os:\n",
      "    \n",
      "    >>> from pathlib import Path  # doctest: +SKIP\n",
      "    >>> filepath = Path('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      "    >>> filepath.parent.mkdir(parents=True, exist_ok=True)  # doctest: +SKIP\n",
      "    >>> df.to_csv(filepath)  # doctest: +SKIP\n",
      "    \n",
      "    >>> import os  # doctest: +SKIP\n",
      "    >>> os.makedirs('folder/subfolder', exist_ok=True)  # doctest: +SKIP\n",
      "    >>> df.to_csv('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(americas_T.to_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150e4bb5-39d5-4b8a-a366-b5a1a75ac3ad",
   "metadata": {},
   "source": [
    "4. Try writing to a CSV file using the code below (giving your own filename). Take a look in the data folder and check it's there.\n",
    "```\n",
    "data_americas.to_csv('data/new_file_name.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "484efc19-edc1-4019-82d0-05a86db786a6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "clear_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "americas_T.to_csv('../data/new_file_name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109dfa8c-5669-4e9d-9ac2-0a25fdcf1b98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
